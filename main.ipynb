{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcfee232",
   "metadata": {},
   "source": [
    "1.1 Extracting a Subset of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5abbece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "DATASET SUBSET EXTRACTION REPORT\n",
      "==================================================\n",
      "\n",
      "Table 1: Number of records in extracted dataset subset\n",
      "---------------------------------------------\n",
      "Category        Records Count  \n",
      "---------------------------------------------\n",
      "Users           17143          \n",
      "Restaurants     3248           \n",
      "Reviews         422898         \n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Section 1.1: Extracting a Subset of the Dataset (Corrected Implementation)\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract_yelp_subset_optimized():\n",
    "   \n",
    "    # File paths\n",
    "    business_file = 'yelp_academic_dataset_business.json'\n",
    "    review_file   = 'yelp_academic_dataset_review.json'\n",
    "    user_file     = 'yelp_academic_dataset_user.json'\n",
    "    \n",
    "    # Step 1: Identify restaurant businesses\n",
    "    restaurant_ids  = set()\n",
    "    restaurant_info = {}\n",
    "    with open(business_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            b = json.loads(line)\n",
    "            if b.get('categories') and 'Restaurant' in b['categories']:\n",
    "                restaurant_ids.add(b['business_id'])\n",
    "                restaurant_info[b['business_id']] = {\n",
    "                    'name': b['name'],\n",
    "                    'categories': b['categories'],\n",
    "                    'city': b.get('city',''),\n",
    "                    'state': b.get('state','')\n",
    "                }\n",
    "    \n",
    "    # Step 2: Count reviews per user and per restaurant\n",
    "    user_restaurant_count    = defaultdict(int)\n",
    "    restaurant_review_count  = defaultdict(int)\n",
    "    with open(review_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            r = json.loads(line)\n",
    "            if r['business_id'] in restaurant_ids:\n",
    "                user_restaurant_count[r['user_id']]       += 1\n",
    "                restaurant_review_count[r['business_id']] += 1\n",
    "    \n",
    "    # Step 3: Select qualified users (>=30 reviews)\n",
    "    qualified_users = {u for u,c in user_restaurant_count.items()    if c>=30}\n",
    "    # Step 4: Select qualified restaurants (>=300 reviews)\n",
    "    qualified_restaurants = {b for b,c in restaurant_review_count.items() if c>=300}\n",
    "    \n",
    "    # Step 5: Extract final reviews\n",
    "    final_reviews = []\n",
    "    with open(review_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            r = json.loads(line)\n",
    "            if r['user_id'] in qualified_users and r['business_id'] in qualified_restaurants:\n",
    "                final_reviews.append(r)\n",
    "    \n",
    "    # Step 6: Build final DataFrames\n",
    "    # Users\n",
    "    final_users = []\n",
    "    with open(user_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            u = json.loads(line)\n",
    "            if u['user_id'] in qualified_users:\n",
    "                final_users.append({\n",
    "                    'user_id':       u['user_id'],\n",
    "                    'name':          u.get('name',''),\n",
    "                    'review_count':  u.get('review_count',0),\n",
    "                    'average_stars': u.get('average_stars',0)\n",
    "                })\n",
    "    users_df       = pd.DataFrame(final_users)\n",
    "    # Restaurants\n",
    "    final_rests    = []\n",
    "    for bid in qualified_restaurants:\n",
    "        info = restaurant_info.get(bid)\n",
    "        if info:\n",
    "            d = info.copy()\n",
    "            d['business_id'] = bid\n",
    "            final_rests.append(d)\n",
    "    restaurants_df = pd.DataFrame(final_rests)\n",
    "    # Reviews\n",
    "    reviews_df     = pd.DataFrame(final_reviews)\n",
    "    \n",
    "    # Save to CSV\n",
    "    users_df.to_csv('users_subset.csv', index=False)\n",
    "    restaurants_df.to_csv('restaurants_subset.csv', index=False)\n",
    "    reviews_df.to_csv('reviews_subset.csv', index=False)\n",
    "    \n",
    "    return users_df, restaurants_df, reviews_df\n",
    "\n",
    "# Execute extraction\n",
    "users_df, restaurants_df, reviews_df = extract_yelp_subset_optimized()\n",
    "\n",
    "def generate_report_table(users_df, restaurants_df, reviews_df):\n",
    "    \"\"\"Generate the required Table 1 report.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"DATASET SUBSET EXTRACTION REPORT\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"\\nTable 1: Number of records in extracted dataset subset\")\n",
    "    print(\"-\" * 45)\n",
    "    print(f\"{'Category':<15} {'Records Count':<15}\")\n",
    "    print(\"-\" * 45)\n",
    "    print(f\"{'Users':<15} {len(users_df):<15}\")\n",
    "    print(f\"{'Restaurants':<15} {len(restaurants_df):<15}\")\n",
    "    print(f\"{'Reviews':<15} {len(reviews_df):<15}\")\n",
    "    print(\"-\" * 45)\n",
    "    return {\n",
    "        'users':       len(users_df),\n",
    "        'restaurants': len(restaurants_df),\n",
    "        'reviews':     len(reviews_df)\n",
    "    }\n",
    "\n",
    "# Generate report\n",
    "report_stats = generate_report_table(users_df, restaurants_df, reviews_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5531f418",
   "metadata": {},
   "source": [
    "1.2 Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5b5b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section 1.2: Data Holdout Split\n",
      "==================================================\n",
      "1. Converting date field to datetime format...\n",
      "   Date range: 2005-03-04 02:06:36 to 2022-01-19 19:42:22\n",
      "2. Sorting by date (oldest first)...\n",
      "   Total reviews: 422898\n",
      "3. Extracting training set (oldest 20,000 records)...\n",
      "   Training set: 20000 reviews (2005-03-04 02:06:36 to 2010-05-28 19:30:18)\n",
      "4. Splitting remaining data into validation and test...\n",
      "   Validation set: 201449 reviews (2010-05-28 19:30:25 to 2016-08-11 17:51:12)\n",
      "   Test set:       201449 reviews (2016-08-11 18:08:38 to 2022-01-19 19:42:22)\n",
      "5. Split verified (chronological order & equal sizes).\n",
      "6. Saving data splits to CSV...\n",
      "   ✓ CSV files saved successfully\n",
      "\n",
      "============================================================\n",
      "Final Data Split Report\n",
      "============================================================\n",
      "   Dataset  Records Start Date   End Date Percentage\n",
      "     Train    20000 2005-03-04 2010-05-28       4.7%\n",
      "Validation   201449 2010-05-28 2016-08-11      47.6%\n",
      "      Test   201449 2016-08-11 2022-01-19      47.6%\n",
      "     Total   422898 2005-03-04 2022-01-19     100.0%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def create_holdout_split(reviews_df):\n",
    "\n",
    "    print(\"Section 1.2: Data Holdout Split\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Step 1: Convert date column to datetime format\n",
    "    reviews_df['date'] = pd.to_datetime(reviews_df['date'])\n",
    "    print(\"1. Converting date field to datetime format...\")\n",
    "    print(f\"   Date range: {reviews_df['date'].min()} to {reviews_df['date'].max()}\")\n",
    "    \n",
    "    # Step 2: Sort by date (oldest first)\n",
    "    print(\"2. Sorting by date (oldest first)...\")\n",
    "    reviews_sorted = reviews_df.sort_values('date').reset_index(drop=True)\n",
    "    total_reviews = len(reviews_sorted)\n",
    "    print(f\"   Total reviews: {total_reviews}\")\n",
    "    \n",
    "    # Step 3: Extract training set (oldest 20,000 records)\n",
    "    print(\"3. Extracting training set (oldest 20,000 records)...\")\n",
    "    train_size = 20000\n",
    "    if total_reviews < train_size:\n",
    "        raise ValueError(f\"Total reviews ({total_reviews}) is less than 20,000!\")\n",
    "    train_data = reviews_sorted.iloc[:train_size].copy()\n",
    "    remaining_data = reviews_sorted.iloc[train_size:].copy()\n",
    "    print(f\"   Training set: {len(train_data)} reviews ({train_data['date'].min()} to {train_data['date'].max()})\")\n",
    "    \n",
    "    # Step 4: Split remaining data equally into validation and test\n",
    "    print(\"4. Splitting remaining data into validation and test...\")\n",
    "    remaining_size = len(remaining_data)\n",
    "    val_size = remaining_size // 2\n",
    "    val_data  = remaining_data.iloc[:val_size].copy()\n",
    "    test_data = remaining_data.iloc[val_size:].copy()\n",
    "    print(f\"   Validation set: {len(val_data)} reviews ({val_data['date'].min()} to {val_data['date'].max()})\")\n",
    "    print(f\"   Test set:       {len(test_data)} reviews ({test_data['date'].min()} to {test_data['date'].max()})\")\n",
    "    \n",
    "    # Step 5: Verify chronological order and equal split\n",
    "    assert train_data['date'].max() <= val_data['date'].min(), \"Train/Val order incorrect\"\n",
    "    assert val_data['date'].max() <= test_data['date'].min(),  \"Val/Test order incorrect\"\n",
    "    size_diff = abs(len(val_data) - len(test_data))\n",
    "    assert size_diff <= 1, f\"Val/Test size difference exceeds 1 ({size_diff})\"\n",
    "    print(\"5. Split verified (chronological order & equal sizes).\")\n",
    "    \n",
    "    # Step 6: Save the splits\n",
    "    print(\"6. Saving data splits to CSV...\")\n",
    "    train_data.to_csv('train_reviews.csv', index=False)\n",
    "    val_data.to_csv('val_reviews.csv',   index=False)\n",
    "    test_data.to_csv('test_reviews.csv',  index=False)\n",
    "    print(\"   ✓ CSV files saved successfully\")\n",
    "    \n",
    "    # Step 7: Generate summary report\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Final Data Split Report\")\n",
    "    print(\"=\" * 60)\n",
    "    summary = {\n",
    "        'Dataset':      ['Train', 'Validation', 'Test', 'Total'],\n",
    "        'Records':      [len(train_data), len(val_data), len(test_data), total_reviews],\n",
    "        'Start Date':   [\n",
    "            train_data['date'].min().strftime('%Y-%m-%d'),\n",
    "            val_data['date'].min().strftime('%Y-%m-%d'),\n",
    "            test_data['date'].min().strftime('%Y-%m-%d'),\n",
    "            reviews_sorted['date'].min().strftime('%Y-%m-%d')\n",
    "        ],\n",
    "        'End Date':     [\n",
    "            train_data['date'].max().strftime('%Y-%m-%d'),\n",
    "            val_data['date'].max().strftime('%Y-%m-%d'),\n",
    "            test_data['date'].max().strftime('%Y-%m-%d'),\n",
    "            reviews_sorted['date'].max().strftime('%Y-%m-%d')\n",
    "        ],\n",
    "        'Percentage': [\n",
    "            f\"{len(train_data)/total_reviews*100:.1f}%\",\n",
    "            f\"{len(val_data)/total_reviews*100:.1f}%\",\n",
    "            f\"{len(test_data)/total_reviews*100:.1f}%\",\n",
    "            \"100.0%\"\n",
    "        ]\n",
    "    }\n",
    "    summary_df = pd.DataFrame(summary)\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# Execute the corrected holdout split\n",
    "# (reviews_df assumed to be the DataFrame from Section 1.1)\n",
    "train_data, val_data, test_data = create_holdout_split(reviews_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f3c710",
   "metadata": {},
   "source": [
    "2.1 Training Word2vec and FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fa7d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table 2: Template for reporting similar words\n",
      "-----------------------------------------------------------------\n",
      "#   | Tasty                        | Give                        \n",
      "    | FastText      Word2Vec      | FastText      Word2Vec     \n",
      "-----------------------------------------------------------------\n",
      "1   | dynasty       yummy         | forgive       add          \n",
      "2   | nasty         delicious     | given         call         \n",
      "3   | deeeelicious  satisfying    | gives         giving       \n",
      "4   | delicious     delish        | gi            consider     \n",
      "5   | flavorful     good          | agave         deserve      \n",
      "6   | delicious-    flavorful     | giwa          make         \n",
      "7   | good-         refreshing    | gave          earn         \n",
      "8   | tasteful      filling       | ive           rate         \n",
      "9   | good          plentiful     | ave           warn         \n",
      "10  | suspicious    strong        | add           kill         \n",
      "11  | delish        scrumptious   | save          lose         \n",
      "12  | delicous      phenomenal    | receive       suggest      \n",
      "13  | pasty         disappointing | relive        ignore       \n",
      "14  | delic         delectable    | gig           buy          \n",
      "15  | flavourful    superb        | remove        allow        \n",
      "\n",
      "--- OOV Token Handling Difference ---\n",
      "Word2Vec could not generate a vector for 'givez' (KeyError).\n",
      "FastText successfully generated a vector for 'givez' with shape (100,).\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except nltk.downloader.DownloadError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    #Step 1:Tokenize using NLTK and Convert to lowercase\n",
    "    return [token.lower() for token in word_tokenize(text)]\n",
    "\n",
    "def train_embeddings_with_defaults(train_data):\n",
    "    \n",
    "    # Preprocess all training texts\n",
    "    train_texts = [preprocess_text(text) for text in train_data['text'] if pd.notna(text)]\n",
    "\n",
    "    # Train Word2Vec model with DEFAULT parameters\n",
    "    word2vec_model = Word2Vec(\n",
    "        sentences=train_texts,\n",
    "        seed=1234\n",
    "    )\n",
    "\n",
    "    # Train FastText model with DEFAULT parameters\n",
    "    fasttext_model = FastText(\n",
    "        sentences=train_texts,\n",
    "        seed=1234\n",
    "    )\n",
    "\n",
    "    return word2vec_model, fasttext_model\n",
    "\n",
    "def find_similar_words(word2vec_model, fasttext_model, target_words=['tasty', 'give']):\n",
    "    \n",
    "    results = {}\n",
    "    for word in target_words:\n",
    "        results[word] = {}\n",
    "        # Word2Vec similarities\n",
    "        try:\n",
    "            w2v_similar = word2vec_model.wv.most_similar(word, topn=15)\n",
    "            results[word]['word2vec'] = [item[0] for item in w2v_similar]\n",
    "        except KeyError:\n",
    "            results[word]['word2vec'] = ['N/A - OOV'] * 15\n",
    "\n",
    "        # FastText similarities\n",
    "        try:\n",
    "            ft_similar = fasttext_model.wv.most_similar(word, topn=15)\n",
    "            results[word]['fasttext'] = [item[0] for item in ft_similar]\n",
    "        except KeyError:\n",
    "            results[word]['fasttext'] = ['N/A - OOV'] * 15\n",
    "\n",
    "    return results\n",
    "\n",
    "def create_similarity_table_exact_format(similar_words):\n",
    "    \n",
    "    print(\"\\nTable 2: Template for reporting similar words\")\n",
    "    print(\"-\" * 65)\n",
    "    print(f\"{'#':<3} | {'Tasty':<28} | {'Give':<28}\")\n",
    "    print(f\"{'':>3} | {'FastText':<13} {'Word2Vec':<13} | {'FastText':<13} {'Word2Vec':<13}\")\n",
    "    print(\"-\" * 65)\n",
    "\n",
    "    tasty_w2v = similar_words['tasty']['word2vec']\n",
    "    tasty_ft = similar_words['tasty']['fasttext']\n",
    "    give_w2v = similar_words['give']['word2vec']\n",
    "    give_ft = similar_words['give']['fasttext']\n",
    "\n",
    "    for i in range(15):\n",
    "        print(f\"{i+1:<3} | {tasty_ft[i]:<13} {tasty_w2v[i]:<13} | {give_ft[i]:<13} {give_w2v[i]:<13}\")\n",
    "\n",
    "\n",
    "#Main Execution Block \n",
    "\n",
    "# 1. Preprocessing and 2. Learn Embeddings\n",
    "word2vec_model, fasttext_model = train_embeddings_with_defaults(train_data)\n",
    "\n",
    "# 3. Find Similar Words and create the report table\n",
    "similar_words_results = find_similar_words(word2vec_model, fasttext_model)\n",
    "create_similarity_table_exact_format(similar_words_results)\n",
    "\n",
    "\n",
    "print(\"\\n--- OOV Token Handling Difference ---\")\n",
    "oov_word = \"givez\"\n",
    "try:\n",
    "    word2vec_model.wv[oov_word]\n",
    "    print(f\"Word2Vec was able to generate a vector for '{oov_word}'.\")\n",
    "except KeyError:\n",
    "    print(f\"Word2Vec could not generate a vector for '{oov_word}' (KeyError).\")\n",
    "\n",
    "try:\n",
    "    ft_vector = fasttext_model.wv[oov_word]\n",
    "    print(f\"FastText successfully generated a vector for '{oov_word}' with shape {ft_vector.shape}.\")\n",
    "except Exception as e:\n",
    "    print(f\"FastText failed to generate a vector for '{oov_word}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93181a3f",
   "metadata": {},
   "source": [
    "3 The Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4744f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Pythonlatest\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "###   PART 3.1: EXPERIMENTING TO SELECT BEST REGRESSOR TYPE   ###\n",
      "\n",
      "Experimenting with 4 regression algorithms...\n",
      "  - Ridge: Validation R² = 0.3556\n",
      "  - Lasso: Validation R² = -0.0117\n",
      "  - RandomForest: Validation R² = 0.3617\n",
      "  - GradientBoosting: Validation R² = 0.3883\n",
      "\n",
      "Experimenting with 4 regression algorithms...\n",
      "  - Ridge: Validation R² = 0.3114\n",
      "  - Lasso: Validation R² = -0.0117\n",
      "  - RandomForest: Validation R² = 0.3026\n",
      "  - GradientBoosting: Validation R² = 0.3371\n",
      "\n",
      "Experimenting with 4 regression algorithms...\n",
      "  - Ridge: Validation R² = 0.3591\n",
      "  - Lasso: Validation R² = -0.0117\n",
      "  - RandomForest: Validation R² = 0.3549\n",
      "  - GradientBoosting: Validation R² = 0.3892\n",
      "\n",
      "Experimenting with 4 regression algorithms...\n",
      "  - Ridge: Validation R² = 0.2828\n",
      "  - Lasso: Validation R² = -0.0117\n",
      "  - RandomForest: Validation R² = 0.2371\n",
      "  - GradientBoosting: Validation R² = 0.2631\n",
      "\n",
      "Experimenting with 4 regression algorithms...\n",
      "  - Ridge: Validation R² = 0.3344\n",
      "  - Lasso: Validation R² = -0.0117\n",
      "  - RandomForest: Validation R² = 0.2429\n",
      "  - GradientBoosting: Validation R² = 0.2920\n",
      "\n",
      "Experimenting with 4 regression algorithms...\n",
      "  - Ridge: Validation R² = 0.4575\n",
      "  - Lasso: Validation R² = -0.0117\n",
      "  - RandomForest: Validation R² = 0.3443\n",
      "  - GradientBoosting: Validation R² = 0.3811\n",
      "\n",
      "================================================================================\n",
      "###   RESULT OF 3.1: SINGLE BEST SYSTEM CHOSEN   ###\n",
      "The regressor to optimize in Section 3.2 is: 'Ridge'\n",
      "================================================================================\n",
      "\n",
      "------------------------------------------------------------\n",
      "Hyperparameter Ranges for Optimization:\n",
      "  - vector_size:          [50, 200]\n",
      "  - window:               [5, 15]\n",
      "  - min_count:            [2, 10]\n",
      "  - epochs:               [10, 40]\n",
      "  - aggregation_type:     ['mean', 'sum', 'max']\n",
      "  - feature_manipulation: ['standard', 'minmax', 'none']\n",
      "  - Regressor 'Ridge' params will be tuned.\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Optimizing: WORD2VEC-SGNS on 3 CPU cores ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 11:49:27,053] Using an existing study with name 'word2vec-SGNS_Ridge' instead of creating a new one.\n",
      "Best trial: 15. Best value: 0.396715:   6%|▋         | 1/16 [51:40<12:55:02, 3100.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 12:41:06,952] Trial 22 finished with value: 0.37881614727518176 and parameters: {'vector_size': 150, 'window': 6, 'min_count': 8, 'epochs': 25, 'aggregation_type': 'mean', 'feature_manipulation': 'minmax', 'ridge_alpha': 0.04796524148291726}. Best is trial 15 with value: 0.3967150298483938.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.396715:  12%|█▎        | 2/16 [52:45<5:06:53, 1315.26s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 12:42:12,331] Trial 21 finished with value: 0.3788239647650289 and parameters: {'vector_size': 150, 'window': 6, 'min_count': 8, 'epochs': 25, 'aggregation_type': 'mean', 'feature_manipulation': 'minmax', 'ridge_alpha': 0.07150029602982691}. Best is trial 15 with value: 0.3967150298483938.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.396715:  19%|█▉        | 3/16 [54:09<2:43:03, 752.59s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 12:43:36,067] Trial 23 finished with value: 0.37881756261997135 and parameters: {'vector_size': 150, 'window': 6, 'min_count': 8, 'epochs': 25, 'aggregation_type': 'mean', 'feature_manipulation': 'minmax', 'ridge_alpha': 0.05231688972444513}. Best is trial 15 with value: 0.3967150298483938.\n",
      "[I 2025-06-28 12:43:36,083] Trial 20 finished with value: 0.37881616061754586 and parameters: {'vector_size': 150, 'window': 6, 'min_count': 8, 'epochs': 25, 'aggregation_type': 'mean', 'feature_manipulation': 'minmax', 'ridge_alpha': 0.0480745419449932}. Best is trial 15 with value: 0.3967150298483938.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.396715:  31%|███▏      | 5/16 [1:43:44<3:34:15, 1168.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 13:33:10,464] Trial 24 finished with value: 0.3955003255322561 and parameters: {'vector_size': 200, 'window': 9, 'min_count': 9, 'epochs': 15, 'aggregation_type': 'mean', 'feature_manipulation': 'minmax', 'ridge_alpha': 0.03121626297228914}. Best is trial 15 with value: 0.3967150298483938.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.396715:  38%|███▊      | 6/16 [1:46:17<2:26:04, 876.42s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 13:35:44,385] Trial 26 finished with value: 0.3954958142975852 and parameters: {'vector_size': 200, 'window': 9, 'min_count': 9, 'epochs': 15, 'aggregation_type': 'mean', 'feature_manipulation': 'minmax', 'ridge_alpha': 0.02091996191240135}. Best is trial 15 with value: 0.3967150298483938.\n",
      "[I 2025-06-28 13:35:44,458] Trial 25 finished with value: 0.3954973689803737 and parameters: {'vector_size': 200, 'window': 9, 'min_count': 9, 'epochs': 15, 'aggregation_type': 'mean', 'feature_manipulation': 'minmax', 'ridge_alpha': 0.02461075322115706}. Best is trial 15 with value: 0.3967150298483938.\n",
      "[I 2025-06-28 13:35:44,615] Trial 27 finished with value: 0.39549621329086926 and parameters: {'vector_size': 200, 'window': 9, 'min_count': 9, 'epochs': 15, 'aggregation_type': 'mean', 'feature_manipulation': 'minmax', 'ridge_alpha': 0.02183249484156032}. Best is trial 15 with value: 0.3967150298483938.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.396715:  56%|█████▋    | 9/16 [2:10:03<1:10:36, 605.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 13:59:30,843] Trial 28 finished with value: 0.3955493407112759 and parameters: {'vector_size': 200, 'window': 9, 'min_count': 9, 'epochs': 15, 'aggregation_type': 'mean', 'feature_manipulation': 'none', 'ridge_alpha': 0.021296396187257552}. Best is trial 15 with value: 0.3967150298483938.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 14:46:44,205] Trial 30 finished with value: 0.36394072878348716 and parameters: {'vector_size': 200, 'window': 12, 'min_count': 10, 'epochs': 30, 'aggregation_type': 'sum', 'feature_manipulation': 'none', 'ridge_alpha': 0.14398626627336378}. Best is trial 15 with value: 0.3967150298483938.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.396715:  62%|██████▎   | 10/16 [2:57:18<1:58:18, 1183.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 14:46:44,829] Trial 31 finished with value: 0.3639407170790724 and parameters: {'vector_size': 200, 'window': 12, 'min_count': 10, 'epochs': 30, 'aggregation_type': 'sum', 'feature_manipulation': 'none', 'ridge_alpha': 0.13555821820466077}. Best is trial 15 with value: 0.3967150298483938.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.396715:  75%|███████▌  | 12/16 [2:58:39<43:02, 645.53s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 14:48:06,694] Trial 29 finished with value: 0.3639407809329316 and parameters: {'vector_size': 200, 'window': 12, 'min_count': 10, 'epochs': 30, 'aggregation_type': 'sum', 'feature_manipulation': 'none', 'ridge_alpha': 0.19497394786336275}. Best is trial 15 with value: 0.3967150298483938.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.396715:  81%|████████▏ | 13/16 [3:00:48<24:55, 498.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 14:50:15,235] Trial 32 finished with value: 0.3620559664576424 and parameters: {'vector_size': 200, 'window': 11, 'min_count': 10, 'epochs': 30, 'aggregation_type': 'sum', 'feature_manipulation': 'none', 'ridge_alpha': 0.11779140315004688}. Best is trial 15 with value: 0.3967150298483938.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.396715:  88%|████████▊ | 14/16 [3:37:55<33:16, 998.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 15:27:21,882] Trial 34 finished with value: 0.3926787865866429 and parameters: {'vector_size': 200, 'window': 10, 'min_count': 10, 'epochs': 20, 'aggregation_type': 'mean', 'feature_manipulation': 'none', 'ridge_alpha': 0.016151828772260093}. Best is trial 15 with value: 0.3967150298483938.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.396715:  88%|████████▊ | 14/16 [3:38:16<33:16, 998.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 15:27:43,011] Trial 33 finished with value: 0.3926853988020088 and parameters: {'vector_size': 200, 'window': 10, 'min_count': 10, 'epochs': 20, 'aggregation_type': 'mean', 'feature_manipulation': 'none', 'ridge_alpha': 0.018572807049815346}. Best is trial 15 with value: 0.3967150298483938.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.396715: 100%|██████████| 16/16 [3:38:56<00:00, 821.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 15:28:24,021] Trial 35 finished with value: 0.3950225590251032 and parameters: {'vector_size': 200, 'window': 10, 'min_count': 9, 'epochs': 20, 'aggregation_type': 'mean', 'feature_manipulation': 'none', 'ridge_alpha': 0.014149845604220517}. Best is trial 15 with value: 0.3967150298483938.\n",
      "\n",
      "--- Optimizing: WORD2VEC-CBOW on 3 CPU cores ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 15:28:27,036] Using an existing study with name 'word2vec-CBOW_Ridge' instead of creating a new one.\n",
      "Best trial: 1. Best value: 0.359813:   6%|▋         | 1/16 [39:08<9:47:10, 2348.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 16:07:35,563] Trial 10 finished with value: 0.1202186235788919 and parameters: {'vector_size': 100, 'window': 6, 'min_count': 6, 'epochs': 35, 'aggregation_type': 'max', 'feature_manipulation': 'none', 'ridge_alpha': 0.01547995767610106}. Best is trial 1 with value: 0.35981291423667594.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.359813:  12%|█▎        | 2/16 [40:04<3:53:17, 999.83s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 16:08:31,533] Trial 8 finished with value: 0.3396699712677972 and parameters: {'vector_size': 150, 'window': 12, 'min_count': 6, 'epochs': 20, 'aggregation_type': 'sum', 'feature_manipulation': 'none', 'ridge_alpha': 0.42867001870601834}. Best is trial 1 with value: 0.35981291423667594.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.359813:  12%|█▎        | 2/16 [40:39<3:53:17, 999.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 16:09:06,423] Trial 9 finished with value: 0.349236234006171 and parameters: {'vector_size': 150, 'window': 14, 'min_count': 4, 'epochs': 35, 'aggregation_type': 'sum', 'feature_manipulation': 'minmax', 'ridge_alpha': 0.1993724109038241}. Best is trial 1 with value: 0.35981291423667594.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.359813:  19%|█▉        | 3/16 [40:57<2:02:58, 567.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 16:09:24,739] Trial 11 finished with value: 0.3445254154317141 and parameters: {'vector_size': 150, 'window': 10, 'min_count': 4, 'epochs': 35, 'aggregation_type': 'sum', 'feature_manipulation': 'standard', 'ridge_alpha': 0.10803916030649124}. Best is trial 1 with value: 0.35981291423667594.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.359813:  31%|███▏      | 5/16 [1:18:05<3:07:35, 1023.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 16:46:32,885] Trial 15 finished with value: 0.33041651625258006 and parameters: {'vector_size': 100, 'window': 7, 'min_count': 4, 'epochs': 20, 'aggregation_type': 'mean', 'feature_manipulation': 'none', 'ridge_alpha': 47.44145453259453}. Best is trial 1 with value: 0.35981291423667594.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.359813:  38%|███▊      | 6/16 [1:19:47<1:58:18, 709.82s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 16:48:14,702] Trial 13 finished with value: 0.3479588622921427 and parameters: {'vector_size': 150, 'window': 7, 'min_count': 9, 'epochs': 35, 'aggregation_type': 'mean', 'feature_manipulation': 'none', 'ridge_alpha': 0.14024033989372553}. Best is trial 1 with value: 0.35981291423667594.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.359813:  44%|████▍     | 7/16 [1:20:19<1:13:14, 488.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 16:48:46,820] Trial 14 finished with value: 0.34169948472646494 and parameters: {'vector_size': 150, 'window': 12, 'min_count': 5, 'epochs': 25, 'aggregation_type': 'sum', 'feature_manipulation': 'standard', 'ridge_alpha': 0.3275526052663715}. Best is trial 1 with value: 0.35981291423667594.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.36691:  50%|█████     | 8/16 [1:20:55<45:54, 344.33s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 16:49:22,918] Trial 12 finished with value: 0.3669103546605259 and parameters: {'vector_size': 200, 'window': 14, 'min_count': 8, 'epochs': 20, 'aggregation_type': 'mean', 'feature_manipulation': 'minmax', 'ridge_alpha': 1.0933052507792302}. Best is trial 12 with value: 0.3669103546605259.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.36691:  56%|█████▋    | 9/16 [1:52:19<1:36:18, 825.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 17:20:45,653] Trial 16 finished with value: 0.2839543608564372 and parameters: {'vector_size': 50, 'window': 6, 'min_count': 8, 'epochs': 25, 'aggregation_type': 'sum', 'feature_manipulation': 'standard', 'ridge_alpha': 0.1339403843574974}. Best is trial 12 with value: 0.3669103546605259.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.36691:  62%|██████▎   | 10/16 [2:05:16<1:21:04, 810.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 17:33:43,588] Trial 17 finished with value: 0.19624628124353605 and parameters: {'vector_size': 200, 'window': 10, 'min_count': 10, 'epochs': 10, 'aggregation_type': 'max', 'feature_manipulation': 'standard', 'ridge_alpha': 4.614641789707977}. Best is trial 12 with value: 0.3669103546605259.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.36691:  69%|██████▉   | 11/16 [2:06:48<49:12, 590.60s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 17:35:15,249] Trial 19 finished with value: 0.19626624031390416 and parameters: {'vector_size': 200, 'window': 10, 'min_count': 10, 'epochs': 10, 'aggregation_type': 'max', 'feature_manipulation': 'minmax', 'ridge_alpha': 1.8687917574033492}. Best is trial 12 with value: 0.3669103546605259.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.36691:  75%|███████▌  | 12/16 [2:08:02<28:54, 433.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 17:36:29,850] Trial 18 finished with value: 0.19439556764153731 and parameters: {'vector_size': 200, 'window': 15, 'min_count': 2, 'epochs': 10, 'aggregation_type': 'max', 'feature_manipulation': 'minmax', 'ridge_alpha': 2.552456368128187}. Best is trial 12 with value: 0.3669103546605259.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.36691:  81%|████████▏ | 13/16 [2:38:39<42:55, 858.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 18:07:06,390] Trial 20 finished with value: 0.19626905473892275 and parameters: {'vector_size': 200, 'window': 10, 'min_count': 10, 'epochs': 10, 'aggregation_type': 'max', 'feature_manipulation': 'minmax', 'ridge_alpha': 2.063704682958652}. Best is trial 12 with value: 0.3669103546605259.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 12. Best value: 0.36691:  88%|████████▊ | 14/16 [2:45:17<23:59, 719.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 18:13:44,432] Trial 21 finished with value: 0.34422184379482423 and parameters: {'vector_size': 200, 'window': 12, 'min_count': 2, 'epochs': 10, 'aggregation_type': 'mean', 'feature_manipulation': 'minmax', 'ridge_alpha': 1.3562295813361072}. Best is trial 12 with value: 0.3669103546605259.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.369949:  94%|█████████▍| 15/16 [2:45:52<08:33, 513.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 18:14:19,848] Trial 23 finished with value: 0.36994943849743533 and parameters: {'vector_size': 200, 'window': 12, 'min_count': 8, 'epochs': 30, 'aggregation_type': 'mean', 'feature_manipulation': 'minmax', 'ridge_alpha': 0.8328403914245459}. Best is trial 23 with value: 0.36994943849743533.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.369949: 100%|██████████| 16/16 [2:46:24<00:00, 624.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 18:14:51,683] Trial 22 finished with value: 0.3589254837252379 and parameters: {'vector_size': 200, 'window': 15, 'min_count': 2, 'epochs': 15, 'aggregation_type': 'mean', 'feature_manipulation': 'minmax', 'ridge_alpha': 1.2225944861800302}. Best is trial 23 with value: 0.36994943849743533.\n",
      "\n",
      "--- Optimizing: FASTTEXT-SGNS on 3 CPU cores ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 18:15:01,546] A new study created in RDB with name: fasttext-SGNS_Ridge\n",
      "Best trial: 0. Best value: 0.158631:   6%|▋         | 1/16 [21:36<5:24:04, 1296.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 18:36:37,585] Trial 0 finished with value: 0.15863114584824234 and parameters: {'vector_size': 100, 'window': 5, 'min_count': 8, 'epochs': 10, 'aggregation_type': 'max', 'feature_manipulation': 'none', 'ridge_alpha': 25.225011318993506}. Best is trial 0 with value: 0.15863114584824234.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.35946:  12%|█▎        | 2/16 [1:15:08<9:25:29, 2423.56s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:30:09,897] Trial 1 finished with value: 0.3594602143722748 and parameters: {'vector_size': 100, 'window': 15, 'min_count': 4, 'epochs': 15, 'aggregation_type': 'sum', 'feature_manipulation': 'standard', 'ridge_alpha': 0.055518472267696205}. Best is trial 1 with value: 0.3594602143722748.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.35946:  19%|█▉        | 3/16 [1:18:02<5:02:27, 1395.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:33:03,366] Trial 4 finished with value: 0.16705875543398185 and parameters: {'vector_size': 100, 'window': 8, 'min_count': 7, 'epochs': 15, 'aggregation_type': 'max', 'feature_manipulation': 'minmax', 'ridge_alpha': 7.664891035838255}. Best is trial 1 with value: 0.3594602143722748.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.380428:  25%|██▌       | 4/16 [1:21:10<3:03:50, 919.18s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:36:11,776] Trial 2 finished with value: 0.38042771242459805 and parameters: {'vector_size': 150, 'window': 5, 'min_count': 9, 'epochs': 40, 'aggregation_type': 'mean', 'feature_manipulation': 'standard', 'ridge_alpha': 26.754494154627302}. Best is trial 2 with value: 0.38042771242459805.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.4081:  31%|███▏      | 5/16 [1:34:51<2:42:02, 883.87s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 19:49:52,936] Trial 3 finished with value: 0.4081004838861565 and parameters: {'vector_size': 200, 'window': 14, 'min_count': 6, 'epochs': 30, 'aggregation_type': 'mean', 'feature_manipulation': 'minmax', 'ridge_alpha': 0.011573378571068662}. Best is trial 3 with value: 0.4081004838861565.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.4081:  38%|███▊      | 6/16 [2:21:18<4:15:10, 1531.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 20:36:20,017] Trial 5 finished with value: 0.15069950347641392 and parameters: {'vector_size': 50, 'window': 6, 'min_count': 5, 'epochs': 40, 'aggregation_type': 'max', 'feature_manipulation': 'none', 'ridge_alpha': 0.9511590866005986}. Best is trial 3 with value: 0.4081004838861565.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.4081:  44%|████▍     | 7/16 [2:26:34<2:50:01, 1133.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 20:41:35,331] Trial 8 finished with value: 0.3848193486867 and parameters: {'vector_size': 100, 'window': 10, 'min_count': 4, 'epochs': 25, 'aggregation_type': 'mean', 'feature_manipulation': 'standard', 'ridge_alpha': 10.420331354437}. Best is trial 3 with value: 0.4081004838861565.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.4081:  50%|█████     | 8/16 [2:45:25<2:31:03, 1132.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 21:00:26,878] Trial 7 finished with value: 0.35162224754463944 and parameters: {'vector_size': 50, 'window': 10, 'min_count': 6, 'epochs': 40, 'aggregation_type': 'mean', 'feature_manipulation': 'minmax', 'ridge_alpha': 0.3167160089911548}. Best is trial 3 with value: 0.4081004838861565.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.4081:  50%|█████     | 8/16 [3:24:15<2:31:03, 1132.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 21:39:16,159] Trial 6 finished with value: 0.3224337804103581 and parameters: {'vector_size': 50, 'window': 15, 'min_count': 6, 'epochs': 35, 'aggregation_type': 'sum', 'feature_manipulation': 'none', 'ridge_alpha': 1.5512581488430035}. Best is trial 3 with value: 0.4081004838861565.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.4081:  62%|██████▎   | 10/16 [3:34:46<2:03:38, 1236.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 21:49:47,247] Trial 9 finished with value: 0.3466654195408848 and parameters: {'vector_size': 100, 'window': 7, 'min_count': 7, 'epochs': 25, 'aggregation_type': 'sum', 'feature_manipulation': 'standard', 'ridge_alpha': 81.47504362881571}. Best is trial 3 with value: 0.4081004838861565.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.4081:  62%|██████▎   | 10/16 [3:34:56<2:03:38, 1236.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 21:49:58,107] Trial 10 finished with value: 0.35281301055376224 and parameters: {'vector_size': 100, 'window': 15, 'min_count': 7, 'epochs': 15, 'aggregation_type': 'sum', 'feature_manipulation': 'standard', 'ridge_alpha': 24.983640483979627}. Best is trial 3 with value: 0.4081004838861565.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.4081:  75%|███████▌  | 12/16 [3:57:30<1:07:24, 1011.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 22:12:32,198] Trial 12 finished with value: 0.3461741109132187 and parameters: {'vector_size': 100, 'window': 9, 'min_count': 5, 'epochs': 10, 'aggregation_type': 'sum', 'feature_manipulation': 'minmax', 'ridge_alpha': 0.029304648679061074}. Best is trial 3 with value: 0.4081004838861565.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.4081:  81%|████████▏ | 13/16 [4:23:29<58:51, 1177.09s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 22:38:30,771] Trial 11 finished with value: 0.19458479722172717 and parameters: {'vector_size': 200, 'window': 9, 'min_count': 5, 'epochs': 35, 'aggregation_type': 'max', 'feature_manipulation': 'minmax', 'ridge_alpha': 0.20484026261844793}. Best is trial 3 with value: 0.4081004838861565.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.4081:  88%|████████▊ | 14/16 [5:11:06<56:08, 1684.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 23:26:07,339] Trial 14 finished with value: 0.4036493083383541 and parameters: {'vector_size': 200, 'window': 11, 'min_count': 2, 'epochs': 30, 'aggregation_type': 'mean', 'feature_manipulation': 'minmax', 'ridge_alpha': 0.010619112514700615}. Best is trial 3 with value: 0.4081004838861565.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.4081:  88%|████████▊ | 14/16 [5:25:11<56:08, 1684.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 23:40:12,987] Trial 13 finished with value: 0.40697719912939256 and parameters: {'vector_size': 200, 'window': 13, 'min_count': 2, 'epochs': 30, 'aggregation_type': 'mean', 'feature_manipulation': 'minmax', 'ridge_alpha': 0.01403848536078922}. Best is trial 3 with value: 0.4081004838861565.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.4081: 100%|██████████| 16/16 [5:26:42<00:00, 1225.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 23:41:43,771] Trial 15 finished with value: 0.4035409218584698 and parameters: {'vector_size': 200, 'window': 12, 'min_count': 2, 'epochs': 30, 'aggregation_type': 'mean', 'feature_manipulation': 'minmax', 'ridge_alpha': 0.013687638650268556}. Best is trial 3 with value: 0.4081004838861565.\n",
      "\n",
      "--- Optimizing: FASTTEXT-CBOW on 3 CPU cores ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-28 23:41:51,581] A new study created in RDB with name: fasttext-CBOW_Ridge\n",
      "Best trial: 3. Best value: 0.28376:   6%|▋         | 1/16 [1:31:31<22:52:59, 5491.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 01:13:23,132] Trial 3 finished with value: 0.2837600369898602 and parameters: {'vector_size': 100, 'window': 13, 'min_count': 4, 'epochs': 20, 'aggregation_type': 'sum', 'feature_manipulation': 'none', 'ridge_alpha': 5.262851408741729}. Best is trial 3 with value: 0.2837600369898602.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.305665:  12%|█▎        | 2/16 [1:39:11<9:50:47, 2531.94s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 01:21:03,247] Trial 1 finished with value: 0.30566490626639153 and parameters: {'vector_size': 200, 'window': 6, 'min_count': 3, 'epochs': 25, 'aggregation_type': 'mean', 'feature_manipulation': 'minmax', 'ridge_alpha': 12.933289997272349}. Best is trial 1 with value: 0.30566490626639153.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.305665:  19%|█▉        | 3/16 [1:41:16<5:10:25, 1432.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 01:23:07,879] Trial 2 finished with value: 0.11848718199721375 and parameters: {'vector_size': 200, 'window': 12, 'min_count': 2, 'epochs': 15, 'aggregation_type': 'max', 'feature_manipulation': 'standard', 'ridge_alpha': 29.60408172811323}. Best is trial 1 with value: 0.30566490626639153.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.305665:  25%|██▌       | 4/16 [1:41:57<2:56:38, 883.17s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 01:23:48,968] Trial 0 finished with value: 0.11101507166474012 and parameters: {'vector_size': 150, 'window': 14, 'min_count': 10, 'epochs': 25, 'aggregation_type': 'max', 'feature_manipulation': 'minmax', 'ridge_alpha': 0.021472312966764044}. Best is trial 1 with value: 0.30566490626639153.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.305665:  25%|██▌       | 4/16 [2:54:48<2:56:38, 883.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 02:36:40,291] Trial 4 finished with value: 0.24883998748864578 and parameters: {'vector_size': 50, 'window': 12, 'min_count': 8, 'epochs': 20, 'aggregation_type': 'mean', 'feature_manipulation': 'minmax', 'ridge_alpha': 2.096027900723861}. Best is trial 1 with value: 0.30566490626639153.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.305665:  31%|███▏      | 5/16 [2:59:28<6:32:33, 2141.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 02:41:19,970] Trial 7 finished with value: 0.09458368166931908 and parameters: {'vector_size': 100, 'window': 5, 'min_count': 8, 'epochs': 30, 'aggregation_type': 'max', 'feature_manipulation': 'standard', 'ridge_alpha': 0.014787184119336083}. Best is trial 1 with value: 0.30566490626639153.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.305665:  38%|███▊      | 6/16 [3:00:02<4:11:24, 1508.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 02:41:54,456] Trial 5 finished with value: 0.29223172072449366 and parameters: {'vector_size': 100, 'window': 12, 'min_count': 5, 'epochs': 15, 'aggregation_type': 'mean', 'feature_manipulation': 'none', 'ridge_alpha': 0.6633775216214779}. Best is trial 1 with value: 0.30566490626639153.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.305665:  44%|████▍     | 7/16 [3:00:38<2:34:02, 1026.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 02:42:29,669] Trial 6 finished with value: 0.27695720560977544 and parameters: {'vector_size': 100, 'window': 12, 'min_count': 2, 'epochs': 10, 'aggregation_type': 'sum', 'feature_manipulation': 'minmax', 'ridge_alpha': 0.12750749583674767}. Best is trial 1 with value: 0.30566490626639153.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.305665:  56%|█████▋    | 9/16 [3:55:36<2:57:16, 1519.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 03:37:27,730] Trial 11 finished with value: 0.07260504923900835 and parameters: {'vector_size': 50, 'window': 9, 'min_count': 9, 'epochs': 10, 'aggregation_type': 'max', 'feature_manipulation': 'minmax', 'ridge_alpha': 0.041545555001233254}. Best is trial 1 with value: 0.30566490626639153.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.305665:  62%|██████▎   | 10/16 [4:01:28<1:55:55, 1159.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 03:43:20,234] Trial 9 finished with value: 0.2760122360663042 and parameters: {'vector_size': 100, 'window': 9, 'min_count': 10, 'epochs': 20, 'aggregation_type': 'sum', 'feature_manipulation': 'minmax', 'ridge_alpha': 0.017341557185667746}. Best is trial 1 with value: 0.30566490626639153.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.310764:  69%|██████▉   | 11/16 [4:05:33<1:13:16, 879.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 03:47:24,760] Trial 8 finished with value: 0.3107635838688697 and parameters: {'vector_size': 200, 'window': 5, 'min_count': 6, 'epochs': 30, 'aggregation_type': 'sum', 'feature_manipulation': 'none', 'ridge_alpha': 0.18999609638230444}. Best is trial 8 with value: 0.3107635838688697.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.310764:  75%|███████▌  | 12/16 [5:15:03<2:05:21, 1880.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 04:56:55,236] Trial 12 finished with value: 0.30355191074661103 and parameters: {'vector_size': 150, 'window': 11, 'min_count': 8, 'epochs': 15, 'aggregation_type': 'sum', 'feature_manipulation': 'standard', 'ridge_alpha': 16.9936325133816}. Best is trial 8 with value: 0.3107635838688697.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 8. Best value: 0.310764:  81%|████████▏ | 13/16 [5:24:25<1:14:02, 1480.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 05:06:16,570] Trial 10 finished with value: 0.11612155560480841 and parameters: {'vector_size': 200, 'window': 15, 'min_count': 5, 'epochs': 40, 'aggregation_type': 'max', 'feature_manipulation': 'none', 'ridge_alpha': 7.680852930065058}. Best is trial 8 with value: 0.3107635838688697.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.327717:  88%|████████▊ | 14/16 [5:31:43<38:51, 1165.78s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 05:13:34,391] Trial 13 finished with value: 0.32771707353283464 and parameters: {'vector_size': 200, 'window': 5, 'min_count': 4, 'epochs': 40, 'aggregation_type': 'mean', 'feature_manipulation': 'standard', 'ridge_alpha': 29.449572870119024}. Best is trial 13 with value: 0.32771707353283464.\n",
      "[I 2025-06-29 05:13:34,419] Trial 14 finished with value: 0.32505963337669286 and parameters: {'vector_size': 200, 'window': 5, 'min_count': 6, 'epochs': 40, 'aggregation_type': 'mean', 'feature_manipulation': 'none', 'ridge_alpha': 73.82107227978045}. Best is trial 13 with value: 0.32771707353283464.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 13. Best value: 0.327717: 100%|██████████| 16/16 [5:46:51<00:00, 1300.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 05:28:42,977] Trial 15 finished with value: 0.3234783349281063 and parameters: {'vector_size': 200, 'window': 5, 'min_count': 6, 'epochs': 40, 'aggregation_type': 'mean', 'feature_manipulation': 'none', 'ridge_alpha': 0.4627166018264548}. Best is trial 13 with value: 0.32771707353283464.\n",
      "\n",
      "--- Optimizing: DOC2VEC-DM on 3 CPU cores ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 05:28:51,385] A new study created in RDB with name: doc2vec-DM_Ridge\n",
      "Best trial: 3. Best value: 0.330255:   6%|▋         | 1/16 [2:01:56<30:29:12, 7316.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 07:30:47,920] Trial 3 finished with value: 0.33025486312275665 and parameters: {'vector_size': 50, 'window': 10, 'min_count': 7, 'epochs': 30, 'feature_manipulation': 'standard', 'ridge_alpha': 36.162837640293446}. Best is trial 3 with value: 0.33025486312275665.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.338762:  12%|█▎        | 2/16 [2:14:47<13:28:49, 3466.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 07:43:39,163] Trial 1 finished with value: 0.3387622925638807 and parameters: {'vector_size': 200, 'window': 15, 'min_count': 10, 'epochs': 30, 'feature_manipulation': 'standard', 'ridge_alpha': 67.29372962941632}. Best is trial 1 with value: 0.3387622925638807.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.388101:  19%|█▉        | 3/16 [2:51:56<10:28:33, 2901.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 08:20:47,242] Trial 2 finished with value: 0.38810107319875686 and parameters: {'vector_size': 150, 'window': 8, 'min_count': 10, 'epochs': 40, 'feature_manipulation': 'none', 'ridge_alpha': 0.4440869103476124}. Best is trial 2 with value: 0.38810107319875686.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.388101:  25%|██▌       | 4/16 [3:02:30<6:41:13, 2006.10s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 08:31:21,886] Trial 0 finished with value: 0.3582765716415377 and parameters: {'vector_size': 150, 'window': 13, 'min_count': 8, 'epochs': 40, 'feature_manipulation': 'minmax', 'ridge_alpha': 0.43254493523372234}. Best is trial 2 with value: 0.38810107319875686.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.388101:  31%|███▏      | 5/16 [3:42:26<6:33:34, 2146.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 09:11:17,751] Trial 4 finished with value: 0.3231029390098348 and parameters: {'vector_size': 150, 'window': 14, 'min_count': 8, 'epochs': 20, 'feature_manipulation': 'none', 'ridge_alpha': 0.013948216547217701}. Best is trial 2 with value: 0.38810107319875686.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.388101:  38%|███▊      | 6/16 [5:01:57<8:26:30, 3039.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 10:30:48,774] Trial 8 finished with value: 0.3107455519209622 and parameters: {'vector_size': 50, 'window': 8, 'min_count': 5, 'epochs': 20, 'feature_manipulation': 'minmax', 'ridge_alpha': 0.08322815410634224}. Best is trial 2 with value: 0.38810107319875686.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.388101:  44%|████▍     | 7/16 [5:07:00<5:21:40, 2144.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 10:35:51,658] Trial 5 finished with value: 0.385790697181537 and parameters: {'vector_size': 150, 'window': 8, 'min_count': 9, 'epochs': 40, 'feature_manipulation': 'none', 'ridge_alpha': 37.163725965695555}. Best is trial 2 with value: 0.38810107319875686.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.388101:  50%|█████     | 8/16 [5:28:43<4:10:12, 1876.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 10:57:34,391] Trial 7 finished with value: 0.38255109476510474 and parameters: {'vector_size': 100, 'window': 6, 'min_count': 5, 'epochs': 35, 'feature_manipulation': 'standard', 'ridge_alpha': 0.5494827485894687}. Best is trial 2 with value: 0.38810107319875686.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.388101:  56%|█████▋    | 9/16 [5:40:45<2:56:48, 1515.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 11:09:36,249] Trial 6 finished with value: 0.38010129835374973 and parameters: {'vector_size': 150, 'window': 7, 'min_count': 4, 'epochs': 35, 'feature_manipulation': 'minmax', 'ridge_alpha': 0.08789097970306378}. Best is trial 2 with value: 0.38810107319875686.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.388101:  62%|██████▎   | 10/16 [6:35:30<3:26:12, 2062.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 12:04:22,090] Trial 11 finished with value: 0.3088510160054877 and parameters: {'vector_size': 100, 'window': 11, 'min_count': 5, 'epochs': 15, 'feature_manipulation': 'minmax', 'ridge_alpha': 0.3513730150712134}. Best is trial 2 with value: 0.38810107319875686.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.388101:  69%|██████▉   | 11/16 [7:15:51<3:00:58, 2171.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 12:44:42,114] Trial 10 finished with value: 0.35137549243625665 and parameters: {'vector_size': 100, 'window': 10, 'min_count': 9, 'epochs': 30, 'feature_manipulation': 'none', 'ridge_alpha': 10.644167274469359}. Best is trial 2 with value: 0.38810107319875686.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.388101:  75%|███████▌  | 12/16 [7:16:37<1:41:40, 1525.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 12:45:28,619] Trial 9 finished with value: 0.3487703530080176 and parameters: {'vector_size': 50, 'window': 5, 'min_count': 4, 'epochs': 30, 'feature_manipulation': 'minmax', 'ridge_alpha': 1.3430882607070742}. Best is trial 2 with value: 0.38810107319875686.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.388101:  81%|████████▏ | 13/16 [7:17:04<53:34, 1071.41s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 12:45:56,192] Trial 13 finished with value: 0.3208361570394688 and parameters: {'vector_size': 200, 'window': 5, 'min_count': 2, 'epochs': 10, 'feature_manipulation': 'none', 'ridge_alpha': 5.389187079840352}. Best is trial 2 with value: 0.38810107319875686.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.388101:  88%|████████▊ | 14/16 [7:45:29<42:05, 1262.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 13:14:20,510] Trial 12 finished with value: 0.3476462362052313 and parameters: {'vector_size': 200, 'window': 12, 'min_count': 5, 'epochs': 30, 'feature_manipulation': 'none', 'ridge_alpha': 5.9101536961827605}. Best is trial 2 with value: 0.38810107319875686.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.390364:  94%|█████████▍| 15/16 [8:46:21<33:02, 1982.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 14:15:12,683] Trial 15 finished with value: 0.3903640561445195 and parameters: {'vector_size': 200, 'window': 8, 'min_count': 10, 'epochs': 40, 'feature_manipulation': 'none', 'ridge_alpha': 4.508279501075975}. Best is trial 15 with value: 0.3903640561445195.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.399271: 100%|██████████| 16/16 [8:48:48<00:00, 1983.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 14:17:40,371] Trial 14 finished with value: 0.39927104216896203 and parameters: {'vector_size': 200, 'window': 5, 'min_count': 2, 'epochs': 40, 'feature_manipulation': 'none', 'ridge_alpha': 4.355805251195806}. Best is trial 14 with value: 0.39927104216896203.\n",
      "\n",
      "--- Optimizing: DOC2VEC-DBOW on 3 CPU cores ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 14:17:46,703] A new study created in RDB with name: doc2vec-DBOW_Ridge\n",
      "Best trial: 0. Best value: 0.464215:   6%|▋         | 1/16 [39:19<9:49:47, 2359.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 14:57:05,704] Trial 0 finished with value: 0.46421476095947145 and parameters: {'vector_size': 200, 'window': 6, 'min_count': 8, 'epochs': 10, 'feature_manipulation': 'standard', 'ridge_alpha': 5.988367160401715}. Best is trial 0 with value: 0.46421476095947145.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.470816:  12%|█▎        | 2/16 [1:14:19<8:35:00, 2207.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 15:32:06,245] Trial 3 finished with value: 0.4708157602662708 and parameters: {'vector_size': 200, 'window': 6, 'min_count': 2, 'epochs': 15, 'feature_manipulation': 'none', 'ridge_alpha': 12.989937285351328}. Best is trial 3 with value: 0.4708157602662708.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.470816:  19%|█▉        | 3/16 [1:27:01<5:35:11, 1547.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 15:44:48,207] Trial 4 finished with value: 0.4633046040033537 and parameters: {'vector_size': 200, 'window': 7, 'min_count': 10, 'epochs': 10, 'feature_manipulation': 'none', 'ridge_alpha': 0.9033183706922638}. Best is trial 3 with value: 0.4708157602662708.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.476288:  25%|██▌       | 4/16 [1:45:39<4:35:29, 1377.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 16:03:25,325] Trial 2 finished with value: 0.47628834042188073 and parameters: {'vector_size': 200, 'window': 12, 'min_count': 7, 'epochs': 20, 'feature_manipulation': 'none', 'ridge_alpha': 0.04362031333841033}. Best is trial 2 with value: 0.47628834042188073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.476288:  31%|███▏      | 5/16 [2:10:26<4:19:47, 1417.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 16:28:12,570] Trial 5 finished with value: 0.4218701654320316 and parameters: {'vector_size': 50, 'window': 7, 'min_count': 6, 'epochs': 15, 'feature_manipulation': 'minmax', 'ridge_alpha': 4.074871900289638}. Best is trial 2 with value: 0.47628834042188073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.476288:  38%|███▊      | 6/16 [2:48:05<4:43:52, 1703.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 17:05:51,469] Trial 8 finished with value: 0.44205424262667004 and parameters: {'vector_size': 100, 'window': 6, 'min_count': 9, 'epochs': 10, 'feature_manipulation': 'standard', 'ridge_alpha': 0.1992286404194013}. Best is trial 2 with value: 0.47628834042188073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.476288:  44%|████▍     | 7/16 [2:52:28<3:04:53, 1232.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 17:10:15,058] Trial 1 finished with value: 0.4646562878053502 and parameters: {'vector_size': 200, 'window': 5, 'min_count': 2, 'epochs': 40, 'feature_manipulation': 'standard', 'ridge_alpha': 0.02510484142771915}. Best is trial 2 with value: 0.47628834042188073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.476288:  50%|█████     | 8/16 [2:57:31<2:04:53, 936.69s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 17:15:18,459] Trial 6 finished with value: 0.4518742066050637 and parameters: {'vector_size': 100, 'window': 5, 'min_count': 2, 'epochs': 25, 'feature_manipulation': 'standard', 'ridge_alpha': 0.5212889992789924}. Best is trial 2 with value: 0.47628834042188073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.476288:  56%|█████▋    | 9/16 [3:16:21<1:56:19, 997.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 17:34:08,203] Trial 7 finished with value: 0.4384589814422024 and parameters: {'vector_size': 50, 'window': 9, 'min_count': 5, 'epochs': 25, 'feature_manipulation': 'minmax', 'ridge_alpha': 0.11184229755313126}. Best is trial 2 with value: 0.47628834042188073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.476288:  62%|██████▎   | 10/16 [3:26:08<1:27:02, 870.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 17:43:55,074] Trial 10 finished with value: 0.42763184330360093 and parameters: {'vector_size': 50, 'window': 14, 'min_count': 10, 'epochs': 10, 'feature_manipulation': 'none', 'ridge_alpha': 0.9094609144702245}. Best is trial 2 with value: 0.47628834042188073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.476288:  69%|██████▉   | 11/16 [4:33:40<2:33:41, 1844.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 18:51:27,463] Trial 9 finished with value: 0.47033364496858976 and parameters: {'vector_size': 150, 'window': 13, 'min_count': 6, 'epochs': 25, 'feature_manipulation': 'none', 'ridge_alpha': 0.17075055570027628}. Best is trial 2 with value: 0.47628834042188073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.476288:  75%|███████▌  | 12/16 [5:04:56<2:03:35, 1853.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 19:22:42,938] Trial 11 finished with value: 0.4330645979075859 and parameters: {'vector_size': 50, 'window': 8, 'min_count': 8, 'epochs': 40, 'feature_manipulation': 'none', 'ridge_alpha': 0.9410953097850924}. Best is trial 2 with value: 0.47628834042188073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.476288:  81%|████████▏ | 13/16 [5:31:59<1:29:11, 1783.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 19:49:46,195] Trial 12 finished with value: 0.4328269232466654 and parameters: {'vector_size': 50, 'window': 10, 'min_count': 10, 'epochs': 40, 'feature_manipulation': 'standard', 'ridge_alpha': 0.75941727499898}. Best is trial 2 with value: 0.47628834042188073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.476288:  88%|████████▊ | 14/16 [5:53:31<54:30, 1635.19s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 20:11:17,544] Trial 13 finished with value: 0.4660724694077364 and parameters: {'vector_size': 150, 'window': 13, 'min_count': 7, 'epochs': 35, 'feature_manipulation': 'none', 'ridge_alpha': 0.013424645582857596}. Best is trial 2 with value: 0.47628834042188073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.476288:  94%|█████████▍| 15/16 [5:54:18<19:16, 1156.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 20:12:05,514] Trial 14 finished with value: 0.4666705650159527 and parameters: {'vector_size': 150, 'window': 11, 'min_count': 4, 'epochs': 20, 'feature_manipulation': 'none', 'ridge_alpha': 92.57373300240266}. Best is trial 2 with value: 0.47628834042188073.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.476288: 100%|██████████| 16/16 [6:05:40<00:00, 1371.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-06-29 20:23:27,628] Trial 15 finished with value: 0.4678796494660422 and parameters: {'vector_size': 150, 'window': 11, 'min_count': 4, 'epochs': 20, 'feature_manipulation': 'none', 'ridge_alpha': 36.14349718025192}. Best is trial 2 with value: 0.47628834042188073.\n",
      "\n",
      "================================================================================\n",
      "FINAL HYPERPARAMETER OPTIMIZATION REPORT\n",
      "         Setting   Best_R2  vector_size  window  min_count  epochs aggregation_type feature_manipulation  ridge_alpha\n",
      "0  word2vec-SGNS  0.396715          200       9         10      20             mean               minmax     0.014504\n",
      "1  word2vec-CBOW  0.369949          200      12          8      30             mean               minmax     0.832840\n",
      "2  fasttext-SGNS  0.408100          200      14          6      30             mean               minmax     0.011573\n",
      "3  fasttext-CBOW  0.327717          200       5          4      40             mean             standard    29.449573\n",
      "4     doc2vec-DM  0.399271          200       5          2      40              NaN                 none     4.355805\n",
      "5   doc2vec-DBOW  0.476288          200      12          7      20              NaN                 none     0.043620\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x1000 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from gensim.models import Word2Vec, FastText, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class RecommenderSystem:\n",
    "   \n",
    "    def __init__(self, random_seed=1234):\n",
    "        self.random_seed = random_seed\n",
    "        np.random.seed(random_seed)\n",
    "        random.seed(random_seed)\n",
    "        self.embedding_type, self.embedding_model, self.aggregation_type = None, None, None\n",
    "        self.feature_scaler, self.regressor, self.chosen_regressor = None, None, None\n",
    "        self.tested_regressors = {}\n",
    "\n",
    "    def _preprocess_text(self, text):\n",
    "        if pd.isna(text): return []\n",
    "        return word_tokenize(text.lower())\n",
    "\n",
    "    def _learn_word_embedding_model(self, train_texts, **hyperparams):\n",
    "        \n",
    "        default_params = {'vector_size': 100, 'window': 5, 'min_count': 5, 'workers': 4, 'epochs': 10, 'seed': self.random_seed}\n",
    "        params = {**default_params, **hyperparams}\n",
    "        ModelClass = Word2Vec if self.embedding_type == 'word2vec' else FastText\n",
    "        self.embedding_model = ModelClass(sentences=train_texts, **params)\n",
    "\n",
    "    def _learn_doc_embedding_model(self, train_texts, **hyperparams):\n",
    "        tagged_docs = [TaggedDocument(words=tokens, tags=[i]) for i, tokens in enumerate(train_texts)]\n",
    "        default_params = {'vector_size': 100, 'window': 8, 'min_count': 5, 'workers': 4, 'epochs': 20, 'seed': self.random_seed}\n",
    "        params = {**default_params, **hyperparams}\n",
    "        self.embedding_model = Doc2Vec(documents=tagged_docs, **params)\n",
    "\n",
    "    def _create_aggregated_embeddings(self, processed_texts):\n",
    "        embeddings = []\n",
    "        for tokens in processed_texts:\n",
    "            token_vectors = [self.embedding_model.wv[token] for token in tokens if token in self.embedding_model.wv]\n",
    "            if not token_vectors:\n",
    "                doc_embedding = np.zeros(self.embedding_model.wv.vector_size)\n",
    "            elif self.aggregation_type == 'mean':\n",
    "                doc_embedding = np.mean(token_vectors, axis=0)\n",
    "            elif self.aggregation_type == 'sum':\n",
    "                doc_embedding = np.sum(token_vectors, axis=0)\n",
    "            elif self.aggregation_type == 'max':\n",
    "                doc_embedding = np.max(token_vectors, axis=0)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported aggregation type: '{self.aggregation_type}'\")\n",
    "            embeddings.append(doc_embedding)\n",
    "        return np.array(embeddings)\n",
    "\n",
    "    def _create_document_vectors(self, processed_texts):\n",
    "        if self.embedding_type == 'doc2vec':\n",
    "            return np.array([self.embedding_model.infer_vector(tokens) for tokens in processed_texts])\n",
    "        else:\n",
    "            return self._create_aggregated_embeddings(processed_texts)\n",
    "\n",
    "    def _apply_feature_manipulation(self, train_vectors, manipulation_type):\n",
    "        self.feature_manipulation_type = manipulation_type\n",
    "        if manipulation_type == 'standard':\n",
    "            self.feature_scaler = StandardScaler()\n",
    "        elif manipulation_type == 'minmax':\n",
    "            self.feature_scaler = MinMaxScaler()\n",
    "        elif manipulation_type == 'none':\n",
    "            self.feature_scaler = None\n",
    "            return train_vectors\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported feature manipulation type: '{manipulation_type}'\")\n",
    "        return self.feature_scaler.fit_transform(train_vectors)\n",
    "\n",
    "    def _experiment_and_select_regressor(self, X_train, y_train, X_val, y_val):\n",
    "        print(\"\\nExperimenting with 4 regression algorithms...\")\n",
    "        regressors_to_test = {\n",
    "            'Ridge': Ridge(random_state=self.random_seed),\n",
    "            'Lasso': Lasso(random_state=self.random_seed),\n",
    "            'RandomForest': RandomForestRegressor(random_state=self.random_seed, n_jobs=-1),\n",
    "            'GradientBoosting': GradientBoostingRegressor(random_state=self.random_seed),\n",
    "        }\n",
    "        for name, model in regressors_to_test.items():\n",
    "            model.fit(X_train, y_train)\n",
    "            r2 = r2_score(y_val, model.predict(X_val))\n",
    "            self.tested_regressors[name] = {'model': model, 'r2': r2}\n",
    "            print(f\"  - {name}: Validation R² = {r2:.4f}\")\n",
    "        self.chosen_regressor = max(self.tested_regressors, key=lambda k: self.tested_regressors[k]['r2'])\n",
    "        self.regressor = self.tested_regressors[self.chosen_regressor]['model']\n",
    "\n",
    "    def fit(self, train_texts, train_ratings, val_texts, val_ratings, \n",
    "            embedding_type, mode, aggregation_type=None, feature_manipulation='standard'):\n",
    "        self.embedding_type, self.aggregation_type = embedding_type, aggregation_type\n",
    "        processed_train_texts = [self._preprocess_text(text) for text in train_texts]\n",
    "        \n",
    "        embedding_hyperparams = {}\n",
    "        if self.embedding_type == 'doc2vec':\n",
    "            embedding_hyperparams['dm'] = 1 if mode == 'DM' else 0\n",
    "            embedding_hyperparams['dbow_words'] = 1 if mode == 'DBOW' else 0\n",
    "            self._learn_doc_embedding_model(processed_train_texts, **embedding_hyperparams)\n",
    "            self.aggregation_type = 'doc2vec'\n",
    "        else:\n",
    "            embedding_hyperparams['sg'] = 1 if mode == 'SGNS' else 0\n",
    "            self._learn_word_embedding_model(processed_train_texts, **embedding_hyperparams)\n",
    "        \n",
    "        processed_val_texts = [self._preprocess_text(text) for text in val_texts]\n",
    "        X_train = self._create_document_vectors(processed_train_texts)\n",
    "        X_val = self._create_document_vectors(processed_val_texts)\n",
    "        X_train_processed = self._apply_feature_manipulation(X_train, feature_manipulation)\n",
    "        X_val_processed = self.feature_scaler.transform(X_val) if self.feature_scaler else X_val\n",
    "        self._experiment_and_select_regressor(X_train_processed, train_ratings, X_val_processed, val_ratings)\n",
    "        return self\n",
    "\n",
    "\n",
    "class HyperparameterOptimizer:\n",
    "    \n",
    "    def __init__(self, train_data, val_data, selected_regressor_name, random_seed=1234):\n",
    "        self.train_data, self.val_data, self.random_seed = train_data, val_data, random_seed\n",
    "        self.selected_regressor_name = selected_regressor_name\n",
    "        self.processed_train_texts = [word_tokenize(str(t).lower()) for t in self.train_data['text']]\n",
    "        self.tagged_train_corpus = [TaggedDocument(d, [i]) for i, d in enumerate(self.processed_train_texts)]\n",
    "        self.n_trials, self.direction = 16, 'maximize'\n",
    "        self.sampler = TPESampler(seed=random_seed)\n",
    "        self.studies = {}\n",
    "\n",
    "    def _report_hyperparameter_ranges(self):\n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "        print(\"Hyperparameter Ranges for Optimization:\")\n",
    "        print(f\"  - vector_size:          [50, 200]\")\n",
    "        print(f\"  - window:               [5, 15]\")\n",
    "        print(f\"  - min_count:            [2, 10]\")\n",
    "        print(f\"  - epochs:               [10, 40]\")\n",
    "        print(f\"  - aggregation_type:     ['mean', 'sum', 'max']\")\n",
    "        print(f\"  - feature_manipulation: ['standard', 'minmax', 'none']\")\n",
    "        print(f\"  - Regressor '{self.selected_regressor_name}' params will be tuned.\")\n",
    "        print(\"-\"*60)\n",
    "\n",
    "    def _objective(self, trial, emb_type, mode):\n",
    "        emb_hp = {'vector_size': trial.suggest_int('vector_size', 50, 200, step=50), 'window': trial.suggest_int('window', 5, 15), 'min_count': trial.suggest_int('min_count', 2, 10), 'epochs': trial.suggest_int('epochs', 10, 40, step=5), 'seed': self.random_seed, 'workers': 1}\n",
    "        if emb_type != 'doc2vec':\n",
    "            agg_type = trial.suggest_categorical('aggregation_type', ['mean', 'sum', 'max'])\n",
    "            emb_hp['sg'] = 1 if mode == 'SGNS' else 0\n",
    "        else:\n",
    "            agg_type, emb_hp['dm'] = 'doc2vec', 1 if mode == 'DM' else 0\n",
    "            emb_hp['dbow_words'] = 1 if mode == 'DBOW' else 0\n",
    "        \n",
    "        feature_manip = trial.suggest_categorical('feature_manipulation', ['standard', 'minmax', 'none'])\n",
    "        \n",
    "        regressor = None\n",
    "        if self.selected_regressor_name == 'RandomForest':\n",
    "        \n",
    "            hp = {'n_estimators': trial.suggest_int('rf_n_estimators', 100, 500, step=100), 'max_depth': trial.suggest_int('rf_max_depth', 10, 30), 'random_state': self.random_seed, 'n_jobs': 1}\n",
    "            regressor = RandomForestRegressor(**hp)\n",
    "        elif self.selected_regressor_name == 'GradientBoosting':\n",
    "            hp = {'n_estimators': trial.suggest_int('gb_n_estimators', 100, 500, step=100), 'learning_rate': trial.suggest_float('gb_lr', 0.01, 0.2, log=True), 'max_depth': trial.suggest_int('gb_max_depth', 3, 8), 'random_state': self.random_seed}\n",
    "            regressor = GradientBoostingRegressor(**hp)\n",
    "        else: # Handle Ridge and Lasso\n",
    "             alpha = trial.suggest_float(f'{self.selected_regressor_name.lower()}_alpha', 1e-2, 1e2, log=True)\n",
    "             ModelClass = Ridge if self.selected_regressor_name == 'Ridge' else Lasso\n",
    "             regressor = ModelClass(alpha=alpha, random_state=self.random_seed)\n",
    "\n",
    "        ModelClass = {'doc2vec': Doc2Vec, 'word2vec': Word2Vec, 'fasttext': FastText}[emb_type]\n",
    "        docs = self.tagged_train_corpus if emb_type == 'doc2vec' else self.processed_train_texts\n",
    "        embedding_model = ModelClass(documents=docs, **emb_hp) if emb_type == 'doc2vec' else ModelClass(sentences=docs, **emb_hp)\n",
    "        \n",
    "        rs_temp = RecommenderSystem(); rs_temp.embedding_model = embedding_model; rs_temp.aggregation_type = agg_type; rs_temp.embedding_type = emb_type\n",
    "        processed_val_texts = [rs_temp._preprocess_text(text) for text in self.val_data['text']]\n",
    "        \n",
    "        X_train = rs_temp._create_document_vectors(self.processed_train_texts)\n",
    "        X_val = rs_temp._create_document_vectors(processed_val_texts)\n",
    "            \n",
    "        if feature_manip != 'none':\n",
    "            scaler = StandardScaler() if feature_manip == 'standard' else MinMaxScaler()\n",
    "            X_train, X_val = scaler.fit_transform(X_train), scaler.transform(X_val)\n",
    "        \n",
    "        regressor.fit(X_train, self.train_data['stars'].values)\n",
    "        return r2_score(self.val_data['stars'].values, regressor.predict(X_val))\n",
    "\n",
    "    def run_all_optimizations(self):\n",
    "        self._report_hyperparameter_ranges()\n",
    "        settings = [{'name': f'{e}-{m}', 'emb': e, 'mode': m} for e, m in [('word2vec','SGNS'), ('word2vec','CBOW'), ('fasttext','SGNS'), ('fasttext','CBOW'), ('doc2vec','DM'), ('doc2vec','DBOW')]]\n",
    "        \n",
    "        for s in settings:\n",
    "            print(f\"\\n--- Optimizing: {s['name'].upper()} on 3 CPU cores ---\")\n",
    "            \n",
    "         \n",
    "            study_name = f\"{s['name']}_{self.selected_regressor_name}\"\n",
    "            storage_path = f\"sqlite:///{study_name}.db\"\n",
    "            \n",
    "            study = optuna.create_study(\n",
    "                study_name=study_name,\n",
    "                storage=storage_path,\n",
    "                direction=self.direction,\n",
    "                sampler=self.sampler,\n",
    "                load_if_exists=True\n",
    "            )\n",
    "            \n",
    "            study.optimize(\n",
    "                lambda trial: self._objective(trial, s['emb'], s['mode']), \n",
    "                n_trials=self.n_trials, \n",
    "                n_jobs=4,\n",
    "                show_progress_bar=True\n",
    "            )\n",
    "            self.studies[s['name']] = study\n",
    "    \n",
    "    def generate_final_report(self):\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"FINAL HYPERPARAMETER OPTIMIZATION REPORT\")\n",
    "        rows = [{'Setting': name, 'Best_R2': study.best_value, **study.best_params} for name, study in self.studies.items()]\n",
    "        print(pd.DataFrame(rows).to_string())\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        axes = axes.flatten()\n",
    "        for i, (name, study) in enumerate(self.studies.items()):\n",
    "            try:\n",
    "                optuna.visualization.plot_param_importances(study, ax=axes[i])\n",
    "                axes[i].set_title(f\"Importance for {name}\")\n",
    "            except: axes[i].set_title(f\"Importance for {name} (No data)\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def demonstrate_section_3_1_experiment(train_data, val_data):\n",
    "    print(\"#\"*80)\n",
    "    print(\"###   PART 3.1: EXPERIMENTING TO SELECT BEST REGRESSOR TYPE   ###\")\n",
    "    configurations = [\n",
    "        {'embedding_type': 'word2vec', 'mode': 'SGNS', 'aggregation_type': 'mean', 'feature_manipulation': 'standard'},\n",
    "        {'embedding_type': 'word2vec', 'mode': 'CBOW', 'aggregation_type': 'mean', 'feature_manipulation': 'standard'},\n",
    "        {'embedding_type': 'fasttext', 'mode': 'SGNS', 'aggregation_type': 'mean', 'feature_manipulation': 'standard'},\n",
    "        {'embedding_type': 'fasttext', 'mode': 'CBOW', 'aggregation_type': 'mean', 'feature_manipulation': 'standard'},\n",
    "        {'embedding_type': 'doc2vec',  'mode': 'DM', 'aggregation_type': 'doc2vec','feature_manipulation': 'standard'},\n",
    "        {'embedding_type': 'doc2vec',  'mode': 'DBOW', 'aggregation_type': 'doc2vec','feature_manipulation': 'standard'}\n",
    "    ]\n",
    "    best_overall_system, best_overall_score = None, -1.0\n",
    "    for config in configurations:\n",
    "        system = RecommenderSystem(random_seed=1234)\n",
    "        system.fit(train_data['text'].values, train_data['stars'].values, val_data['text'].values, val_data['stars'].values, **config)\n",
    "        current_score = system.tested_regressors[system.chosen_regressor]['r2']\n",
    "        if current_score > best_overall_score:\n",
    "            best_overall_score, best_overall_system = current_score, system\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"###   RESULT OF 3.1: SINGLE BEST SYSTEM CHOSEN   ###\")\n",
    "    print(f\"The regressor to optimize in Section 3.2 is: '{best_overall_system.chosen_regressor}'\")\n",
    "    print(\"=\"*80)\n",
    "    return best_overall_system.chosen_regressor\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        train_data = pd.read_csv(\"train_reviews.csv\")\n",
    "        val_data   = pd.read_csv(\"val_reviews.csv\")\n",
    "        \n",
    "        chosen_regressor_name = demonstrate_section_3_1_experiment(train_data, val_data)\n",
    "        \n",
    "        optimizer = HyperparameterOptimizer(train_data, val_data, selected_regressor_name=chosen_regressor_name)\n",
    "        optimizer.run_all_optimizations()\n",
    "        optimizer.generate_final_report()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\nERROR: CSV files not found. Please run Section 1 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068142d6",
   "metadata": {},
   "source": [
    "4 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e4915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "###   PATCH: RE-TRAINING FINAL 6 MODELS USING BEST PARAMS FROM SECTION 3   ###\n",
      "################################################################################\n",
      "\n",
      "--- Re-training final model for: 'word2vec-SGNS' ---\n",
      "--- Model for 'word2vec-SGNS' successfully re-trained and stored. ---\n",
      "\n",
      "--- Re-training final model for: 'word2vec-CBOW' ---\n",
      "--- Model for 'word2vec-CBOW' successfully re-trained and stored. ---\n",
      "\n",
      "--- Re-training final model for: 'fasttext-SGNS' ---\n",
      "--- Model for 'fasttext-SGNS' successfully re-trained and stored. ---\n",
      "\n",
      "--- Re-training final model for: 'fasttext-CBOW' ---\n",
      "--- Model for 'fasttext-CBOW' successfully re-trained and stored. ---\n",
      "\n",
      "--- Re-training final model for: 'doc2vec-DM' ---\n",
      "--- Model for 'doc2vec-DM' successfully re-trained and stored. ---\n",
      "\n",
      "--- Re-training final model for: 'doc2vec-DBOW' ---\n",
      "--- Model for 'doc2vec-DBOW' successfully re-trained and stored. ---\n",
      "\n",
      "--- Starting Comprehensive Evaluation of All 6 Optimized Systems ---\n",
      "Evaluating 'word2vec-SGNS' on 'Train' data...\n",
      "Evaluating 'word2vec-SGNS' on 'Validation' data...\n",
      "Evaluating 'word2vec-SGNS' on 'Test' data...\n",
      "Evaluating 'word2vec-CBOW' on 'Train' data...\n",
      "Evaluating 'word2vec-CBOW' on 'Validation' data...\n",
      "Evaluating 'word2vec-CBOW' on 'Test' data...\n",
      "Evaluating 'fasttext-SGNS' on 'Train' data...\n",
      "Evaluating 'fasttext-SGNS' on 'Validation' data...\n",
      "Evaluating 'fasttext-SGNS' on 'Test' data...\n",
      "Evaluating 'fasttext-CBOW' on 'Train' data...\n",
      "Evaluating 'fasttext-CBOW' on 'Validation' data...\n",
      "Evaluating 'fasttext-CBOW' on 'Test' data...\n",
      "Evaluating 'doc2vec-DM' on 'Train' data...\n",
      "Evaluating 'doc2vec-DM' on 'Validation' data...\n",
      "Evaluating 'doc2vec-DM' on 'Test' data...\n",
      "Evaluating 'doc2vec-DBOW' on 'Train' data...\n",
      "Evaluating 'doc2vec-DBOW' on 'Validation' data...\n",
      "Evaluating 'doc2vec-DBOW' on 'Test' data...\n",
      "\n",
      "--- Evaluation Summary ---\n",
      "                    MAE      RMSE      MAPE        R2       CCC  Pearson_r  \\\n",
      "doc2vec-DBOW   0.611098  0.768071  0.202922  0.457771  0.620296   0.689964   \n",
      "fasttext-SGNS  0.641733  0.800760  0.207421  0.410635  0.594877   0.663067   \n",
      "word2vec-SGNS  0.647587  0.808100  0.210211  0.399781  0.584727   0.654488   \n",
      "doc2vec-DM     0.649612  0.810684  0.209720  0.395936  0.590080   0.652319   \n",
      "word2vec-CBOW  0.660524  0.825462  0.214685  0.373712  0.572303   0.634514   \n",
      "fasttext-CBOW  0.690864  0.861112  0.225052  0.318448  0.519056   0.597190   \n",
      "\n",
      "               Spearman_rho  Kendall_tau    NDCG@1    NDCG@3    NDCG@5  \\\n",
      "doc2vec-DBOW       0.567981     0.484550  0.957458  0.960457  0.964008   \n",
      "fasttext-SGNS      0.567213     0.484102  0.956032  0.959989  0.963575   \n",
      "word2vec-SGNS      0.558758     0.476273  0.953701  0.958631  0.962225   \n",
      "doc2vec-DM         0.540394     0.459282  0.954581  0.957077  0.960719   \n",
      "word2vec-CBOW      0.551344     0.468605  0.953354  0.957443  0.961268   \n",
      "fasttext-CBOW      0.519871     0.439370  0.947665  0.952614  0.956896   \n",
      "\n",
      "                NDCG@10  \n",
      "doc2vec-DBOW   0.971660  \n",
      "fasttext-SGNS  0.971277  \n",
      "word2vec-SGNS  0.970376  \n",
      "doc2vec-DM     0.968963  \n",
      "word2vec-CBOW  0.969429  \n",
      "fasttext-CBOW  0.965914  \n",
      "\n",
      "================================================================================\n",
      "TOP-10 RESTAURANT RECOMMENDATIONS FOR USER TASHALEE\n",
      "Using best performing system based on Test R2: 'doc2vec-DBOW'\n",
      "\n",
      "Top-10 Recommended Restaurants:\n",
      "                      name  predicted_rating\n",
      "                     Stock          5.674197\n",
      "  Caleb's American Kitchen          5.553112\n",
      "           The Quesadillas          5.493170\n",
      "                  Julienne          5.470941\n",
      "House of Blues New Orleans          5.448084\n",
      "               Half & Half          5.439425\n",
      "           3 Days in Paris          5.429898\n",
      "         Five Points Pizza          5.409881\n",
      "      Mandina's Restaurant          5.407933\n",
      "               Asian Pearl          5.404843\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "import torchmetrics.functional as tmf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models import Word2Vec, FastText\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from torchmetrics.functional.retrieval import retrieval_normalized_dcg\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Part1:Reconstructing optimized models from the results of section 3\n",
    "\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"###   PATCH: RE-TRAINING FINAL 6 MODELS USING BEST PARAMS FROM SECTION 3   ###\")\n",
    "print(\"#\"*80)\n",
    "\n",
    "# This code assumes that the 'optimizer' object and data dataframes from the execution of previous sections are present in memory\n",
    "final_trained_systems = {}\n",
    "\n",
    "# Initial preprocessing of training texts, which is the same for all models\n",
    "processed_train_texts = [word_tokenize(str(t).lower()) for t in train_data['text']]\n",
    "tagged_train_corpus = [TaggedDocument(d, [i]) for i, d in enumerate(processed_train_texts)]\n",
    "chosen_regressor_name = optimizer.selected_regressor_name\n",
    "\n",
    "for name, study in optimizer.studies.items():\n",
    "    print(f\"\\n--- Re-training final model for: '{name}' ---\")\n",
    "    best_params = study.best_params\n",
    "    emb_type, mode = name.split('-')\n",
    "\n",
    "    # 1.Train the Embedding model with the best parameters\n",
    "    emb_hp = {\n",
    "        'vector_size': best_params.get('vector_size'), 'window': best_params.get('window'),\n",
    "        'min_count': best_params.get('min_count'), 'epochs': best_params.get('epochs'),\n",
    "        'seed': 1234, 'workers': 4\n",
    "    }\n",
    "    if emb_type == 'doc2vec':\n",
    "        emb_hp['dm'] = 1 if mode == 'DM' else 0\n",
    "        embedding_model = Doc2Vec(documents=tagged_train_corpus, **emb_hp)\n",
    "    else:\n",
    "        emb_hp['sg'] = 1 if mode == 'SGNS' else 0\n",
    "        ModelClass = Word2Vec if emb_type == 'word2vec' else FastText\n",
    "        embedding_model = ModelClass(sentences=processed_train_texts, **emb_hp)\n",
    "\n",
    "    # 2.Create document vectors\n",
    "    rs_temp = RecommenderSystem()\n",
    "    rs_temp.embedding_model = embedding_model\n",
    "    rs_temp.aggregation_type = best_params.get('aggregation_type', 'doc2vec')\n",
    "    rs_temp.embedding_type = emb_type\n",
    "    X_train = rs_temp._create_document_vectors(processed_train_texts)\n",
    "\n",
    "    #3.Train the Scaler\n",
    "    scaler = None\n",
    "    feature_manip = best_params.get('feature_manipulation')\n",
    "    if feature_manip == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "    elif feature_manip == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "    #4.Train the Regressor\n",
    "    if chosen_regressor_name == 'RandomForest':\n",
    "        hp = {k.replace('rf_', ''): v for k, v in best_params.items() if k.startswith('rf_')}\n",
    "        regressor = RandomForestRegressor(random_state=1234, n_jobs=-1, **hp)\n",
    "    elif chosen_regressor_name == 'GradientBoosting':\n",
    "        hp = {k.replace('gb_', ''): v for k, v in best_params.items() if k.startswith('gb_')}\n",
    "        regressor = GradientBoostingRegressor(random_state=1234, **hp)\n",
    "    else:\n",
    "        alpha_key = f'{chosen_regressor_name.lower()}_alpha'\n",
    "        alpha = best_params.get(alpha_key)\n",
    "        ModelClass = Ridge if chosen_regressor_name == 'Ridge' else Lasso\n",
    "        regressor = ModelClass(alpha=alpha, random_state=1234)\n",
    "    regressor.fit(X_train, train_data['stars'].values)\n",
    "\n",
    "    #5.Store all trained components\n",
    "    final_trained_systems[name] = {\n",
    "        'embedding_model': embedding_model, 'scaler': scaler, 'regressor': regressor\n",
    "    }\n",
    "    print(f\"--- Model for '{name}' successfully re-trained and stored. ---\")\n",
    "\n",
    "#Part 2:Comprehensive evaluation class \n",
    "\n",
    "class ComprehensiveEvaluator:\n",
    "    \"\"\"\n",
    "    A complete and methodologically correct evaluator for the 6 optimized systems.\n",
    "    \"\"\"\n",
    "    def __init__(self, optimized_systems, best_params_per_system, train_data, val_data, test_data, users_df, restaurants_df):\n",
    "        self.optimized_systems = optimized_systems\n",
    "        self.best_params = best_params_per_system\n",
    "        self.train_data, self.val_data, self.test_data = train_data, val_data, test_data\n",
    "        self.users_df, self.restaurants_df = users_df, restaurants_df\n",
    "        self.evaluation_results = {}\n",
    "        self.system_names = list(self.optimized_systems.keys())\n",
    "\n",
    "    def _preprocess_text(self, text):\n",
    "        if pd.isna(text): return []\n",
    "        return word_tokenize(str(text).lower())\n",
    "\n",
    "    def _predict_with_components(self, system_name, texts):\n",
    "        system_components = self.optimized_systems.get(system_name)\n",
    "        if not system_components:\n",
    "            print(f\"Warning: Components for system '{system_name}' not found. Skipping prediction.\")\n",
    "            return np.zeros(len(texts))\n",
    "\n",
    "        embedding_model, scaler, regressor = system_components.get('embedding_model'), system_components.get('scaler'), system_components.get('regressor')\n",
    "        if embedding_model is None or regressor is None:\n",
    "            raise ValueError(f\"Incomplete components for system '{system_name}'\")\n",
    "\n",
    "        embedding_type = 'doc2vec' if isinstance(embedding_model, Doc2Vec) else 'word_based'\n",
    "        aggregation_type = self.best_params[system_name].get('aggregation_type', 'doc2vec')\n",
    "        processed_texts = [self._preprocess_text(text) for text in texts]\n",
    "\n",
    "        if embedding_type == 'doc2vec':\n",
    "            embeddings = np.array([embedding_model.infer_vector(tokens) for tokens in processed_texts])\n",
    "        else:\n",
    "            vecs = []\n",
    "            for tokens in processed_texts:\n",
    "                word_vecs = [embedding_model.wv[t] for t in tokens if t in embedding_model.wv]\n",
    "                if not word_vecs: vecs.append(np.zeros(embedding_model.vector_size))\n",
    "                elif aggregation_type == 'mean': vecs.append(np.mean(word_vecs, axis=0))\n",
    "                elif aggregation_type == 'sum': vecs.append(np.sum(word_vecs, axis=0))\n",
    "                elif aggregation_type == 'max': vecs.append(np.max(word_vecs, axis=0))\n",
    "            embeddings = np.array(vecs)\n",
    "        \n",
    "        if scaler:\n",
    "            embeddings = scaler.transform(embeddings)\n",
    "        return regressor.predict(embeddings)\n",
    "\n",
    "    def calculate_regression_metrics(self, y_true, y_pred):\n",
    "        preds_t, target_t = torch.tensor(y_pred, dtype=torch.float32), torch.tensor(y_true, dtype=torch.float32)\n",
    "        return {\n",
    "            'MAE': torchmetrics.MeanAbsoluteError()(preds_t, target_t).item(),\n",
    "            'RMSE': torch.sqrt(torchmetrics.MeanSquaredError()(preds_t, target_t)).item(),\n",
    "            'MAPE': torchmetrics.MeanAbsolutePercentageError()(preds_t, target_t).item(),\n",
    "            'R2': torchmetrics.R2Score()(preds_t, target_t).item(),\n",
    "            'CCC': torchmetrics.ConcordanceCorrCoef()(preds_t, target_t).item(),\n",
    "            'Pearson_r': torchmetrics.PearsonCorrCoef()(preds_t, target_t).item(),\n",
    "        }\n",
    "\n",
    "    def calculate_ranking_metrics(self, df_with_preds):\n",
    "        user_groups = df_with_preds.groupby('user_id')\n",
    "        all_user_metrics = []\n",
    "        for _, group in user_groups:\n",
    "            if len(group) < 2: continue\n",
    "            y_true, y_pred = group['stars'].values, group['predicted_stars'].values\n",
    "            spearman, _ = spearmanr(y_true, y_pred)\n",
    "            kendall, _ = kendalltau(y_true, y_pred)\n",
    "            preds_t, target_t = torch.tensor(y_pred, dtype=torch.float32), torch.tensor(y_true, dtype=torch.float32)\n",
    "            ndcg_scores = {f'NDCG@{k}': retrieval_normalized_dcg(preds_t, target_t, top_k=k).item() for k in [1, 3, 5, 10]}\n",
    "            all_user_metrics.append({'Spearman_rho': 0 if np.isnan(spearman) else spearman, 'Kendall_tau': 0 if np.isnan(kendall) else kendall, **ndcg_scores})\n",
    "        if not all_user_metrics: return {k: 0.0 for k in ['Spearman_rho', 'Kendall_tau', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10']}\n",
    "        return pd.DataFrame(all_user_metrics).mean().to_dict()\n",
    "\n",
    "    def evaluate_all_systems(self):\n",
    "        print(\"\\n--- Starting Comprehensive Evaluation of All 6 Optimized Systems ---\")\n",
    "        datasets = {'Train': self.train_data, 'Validation': self.val_data, 'Test': self.test_data}\n",
    "        for system_name in self.system_names:\n",
    "            self.evaluation_results[system_name] = {}\n",
    "            for set_name, dataset in datasets.items():\n",
    "                print(f\"Evaluating '{system_name}' on '{set_name}' data...\")\n",
    "                predictions = self._predict_with_components(system_name, dataset['text'].values)\n",
    "                reg_metrics = self.calculate_regression_metrics(dataset['stars'].values, predictions)\n",
    "                dataset_with_preds = dataset.copy(); dataset_with_preds['predicted_stars'] = predictions\n",
    "                rank_metrics = self.calculate_ranking_metrics(dataset_with_preds)\n",
    "                self.evaluation_results[system_name][set_name] = {**reg_metrics, **rank_metrics}\n",
    "\n",
    "    def recommend_restaurants_for_tashalee(self):\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"TOP-10 RESTAURANT RECOMMENDATIONS FOR USER TASHALEE\")\n",
    "        try:\n",
    "            best_system_name = max(self.evaluation_results, key=lambda s: self.evaluation_results[s]['Test']['R2'])\n",
    "            print(f\"Using best performing system based on Test R2: '{best_system_name}'\")\n",
    "            restaurants_to_rate = self.val_data.drop_duplicates(subset=['business_id']).merge(self.restaurants_df[['business_id', 'name']], on='business_id')\n",
    "            predictions = self._predict_with_components(best_system_name, restaurants_to_rate['text'].values)\n",
    "            restaurants_to_rate['predicted_rating'] = predictions\n",
    "            print(\"\\nTop-10 Recommended Restaurants:\")\n",
    "            print(restaurants_to_rate.nlargest(10, 'predicted_rating')[['name', 'predicted_rating']].to_string(index=False))\n",
    "        except Exception as e:\n",
    "            print(f\"Could not generate recommendations for Tashalee. Error: {e}\")\n",
    "\n",
    "    def generate_full_report(self):\n",
    "        self.evaluate_all_systems()\n",
    "        print(\"\\n--- Evaluation Summary ---\")\n",
    "        # Example: Displaying a summary of results for the test set\n",
    "        test_results = {name: results['Test'] for name, results in self.evaluation_results.items() if 'Test' in results}\n",
    "        if test_results:\n",
    "            print(pd.DataFrame.from_dict(test_results, orient='index').sort_values(by='R2', ascending=False))\n",
    "        self.recommend_restaurants_for_tashalee()\n",
    "\n",
    "#   Part 3: Final execution block\n",
    "# Initialize the evaluator using the reconstructed models\n",
    "evaluator = ComprehensiveEvaluator(\n",
    "    optimized_systems=final_trained_systems,\n",
    "    best_params_per_system={name: study.best_params for name, study in optimizer.studies.items()},\n",
    "    train_data=train_data,\n",
    "    val_data=val_data,\n",
    "    test_data=test_data,\n",
    "    users_df=users_df,\n",
    "    restaurants_df=restaurants_df\n",
    ")\n",
    "# Execute the complete evaluation and reporting\n",
    "evaluator.generate_full_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee190763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: All results have been safely saved to the file 'optimizer_results.pkl'\n",
      "It is now SAFE to restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# File path to save the results\n",
    "results_filepath = 'optimizer_results.pkl'\n",
    "\n",
    "# Data to save\n",
    "data_to_save = {\n",
    "    'optimizer': optimizer,\n",
    "    'train_data': train_data,\n",
    "    'val_data': val_data,\n",
    "    'test_data': test_data,\n",
    "    'users_df': users_df,\n",
    "    'restaurants_df': restaurants_df\n",
    "}\n",
    "\n",
    "try:\n",
    "    with open(results_filepath, 'wb') as f:\n",
    "        pickle.dump(data_to_save, f)\n",
    "    print(f\"SUCCESS: All results have been safely saved to the file '{results_filepath}'\")\n",
    "    print(\"It is now SAFE to restart the kernel.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not save the results. DO NOT RESTART THE KERNEL. Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
